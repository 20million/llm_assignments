{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow and Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Uncomment and use it\n",
    "#!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: tensorflow\r\n",
      "Version: 2.11.1\r\n",
      "Summary: TensorFlow is an open source machine learning framework for everyone.\r\n",
      "Home-page: https://www.tensorflow.org/\r\n",
      "Author: Google Inc.\r\n",
      "Author-email: packages@tensorflow.org\r\n",
      "License: Apache 2.0\r\n",
      "Location: /Users/shankar/.pyenv/versions/3.8-dev/lib/python3.8/site-packages\r\n",
      "Requires: absl-py, astunparse, flatbuffers, gast, google-pasta, grpcio, h5py, keras, libclang, numpy, opt-einsum, packaging, protobuf, setuptools, six, tensorboard, tensorflow-estimator, tensorflow-io-gcs-filesystem, termcolor, typing-extensions, wrapt\r\n",
      "Required-by: \r\n"
     ]
    }
   ],
   "source": [
    "!pip show tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "%matplotlib inline  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Constants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tf.constant creates constant values, these values do not change\n",
    "or update during optimization process(training phase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([50 10], shape=(2,), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[1 2 3]\n",
      " [3 4 7]], shape=(2, 3), dtype=int32)\n",
      "2.11.1\n",
      "[[1 2 3]\n",
      " [3 4 7]]\n",
      "(2, 3)\n"
     ]
    }
   ],
   "source": [
    "a = tf.constant([50,10])\n",
    "print(a)\n",
    "b = tf.constant([[1,2,3],[3,4,7]])\n",
    "print(b)\n",
    "print(tf.__version__)\n",
    "print(b.numpy())\n",
    "print(b.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Few things that we can do with the tensors at the runtime:\n",
    "1. Directly get a numpy value of the tensor\n",
    "2. dtype : data type of the tensor(int16/int32/float32/float64)\n",
    "3. shape: shape of the tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a in tensorflow ==> tf.Tensor([50 10], shape=(2,), dtype=int32)\n",
      "numpy value of a ==> [50 10]\n",
      "dtype of a ==> <dtype: 'int32'>\n",
      "shape of a ==> (2,)\n"
     ]
    }
   ],
   "source": [
    "print('a in tensorflow ==>', a)\n",
    "print('numpy value of a ==>', a.numpy())\n",
    "print('dtype of a ==>', a.dtype)\n",
    "print('shape of a ==>', a.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use inbuild tf.XX() function to create constant tensors, just like numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor of Ones: \n",
      " tf.Tensor(\n",
      "[[1. 1.]\n",
      " [1. 1.]], shape=(2, 2), dtype=float32)\n",
      "Tensor of Zeros: \n",
      " tf.Tensor(\n",
      "[[0. 0.]\n",
      " [0. 0.]], shape=(2, 2), dtype=float32)\n",
      "Random normal values \n",
      " tf.Tensor(\n",
      "[[5.527405  4.7836804]\n",
      " [3.4078662 3.9296103]\n",
      " [5.608993  4.038655 ]], shape=(3, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print('Tensor of Ones: \\n',tf.ones(shape=(2, 2)))\n",
    "print('Tensor of Zeros: \\n',tf.zeros(shape=(2, 2)))\n",
    "print('Random normal values \\n', tf.random.normal(shape=(3, 2),\n",
    "                                                  mean=5, \n",
    "                                                  stddev=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We generally create a variable with some values, call it initialized values, \n",
    "convert this constant tensor into a variable and then mutate the variable by using special functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.Variable(5) # Simple variable\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'Variable:0' shape=(2, 2) dtype=float32, numpy=\n",
      "array([[ 0.8404092, -1.2949399],\n",
      "       [ 0.5561162, -0.8268858]], dtype=float32)>\n"
     ]
    }
   ],
   "source": [
    "#randomly initialized variable, like we need for our weights\n",
    "w = tf.Variable(tf.random.normal(shape=(2, 2))) \n",
    "print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'Variable:0' shape=() dtype=int32, numpy=5>\n",
      "New value <tf.Variable 'UnreadVariable' shape=() dtype=int32, numpy=2>\n",
      "increment by 1 <tf.Variable 'UnreadVariable' shape=() dtype=int32, numpy=6>\n",
      "Decrement by 2 <tf.Variable 'UnreadVariable' shape=() dtype=int32, numpy=3>\n"
     ]
    }
   ],
   "source": [
    "m = tf.Variable(5) # Simple variable\n",
    "print(m)\n",
    "\n",
    "m = tf.Variable(5) \n",
    "print('New value', m.assign(2))\n",
    "\n",
    "m = tf.Variable(5) \n",
    "print('increment by 1', m.assign_add(1))\n",
    "\n",
    "m = tf.Variable(5) \n",
    "print('Decrement by 2', m.assign_sub(2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression Model building in TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#This step is for data creation, x and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#This step is for data creation, x and y\n",
    "import numpy as np\n",
    "x_train= np.array(range(5000,5100)).reshape(-1,1)\n",
    "noise=np.random.normal(500, 10, 100)\n",
    "y_train=[3*x+noise[x-5000] for x in x_train]\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.title(\"x_train vs y_train data\")\n",
    "plt.plot(x_train, y_train, 'b.')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 0, loss  128892496.0,  W : [[0.9653369]], b  [1.0000226]\n",
      "epoch : 1, loss  116081568.0,  W : [[1.0741464]], b  [1.0000442]\n",
      "epoch : 2, loss  104543952.0,  W : [[1.177407]], b  [1.0000647]\n",
      "epoch : 3, loss  94153072.0,  W : [[1.2754017]], b  [1.0000842]\n",
      "epoch : 4, loss  84794976.0,  W : [[1.368399]], b  [1.0001025]\n",
      "epoch : 5, loss  76367008.0,  W : [[1.4566537]], b  [1.00012]\n",
      "epoch : 6, loss  68776712.0,  W : [[1.5404078]], b  [1.0001366]\n",
      "epoch : 7, loss  61940828.0,  W : [[1.6198907]], b  [1.0001523]\n",
      "epoch : 8, loss  55784392.0,  W : [[1.6953202]], b  [1.0001673]\n",
      "epoch : 9, loss  50239852.0,  W : [[1.7669032]], b  [1.0001814]\n",
      "epoch : 10, loss  45246404.0,  W : [[1.8348355]], b  [1.0001949]\n",
      "epoch : 11, loss  40749256.0,  W : [[1.8993036]], b  [1.0002077]\n",
      "epoch : 12, loss  36699100.0,  W : [[1.960484]], b  [1.0002198]\n",
      "epoch : 13, loss  33051494.0,  W : [[2.0185444]], b  [1.0002313]\n",
      "epoch : 14, loss  29766438.0,  W : [[2.073644]], b  [1.0002422]\n",
      "epoch : 15, loss  26807896.0,  W : [[2.1259336]], b  [1.0002526]\n",
      "epoch : 16, loss  24143400.0,  W : [[2.1755567]], b  [1.0002624]\n",
      "epoch : 17, loss  21743742.0,  W : [[2.222649]], b  [1.0002717]\n",
      "epoch : 18, loss  19582590.0,  W : [[2.26734]], b  [1.0002805]\n",
      "epoch : 19, loss  17636242.0,  W : [[2.3097517]], b  [1.0002888]\n",
      "epoch : 20, loss  15883343.0,  W : [[2.3500006]], b  [1.0002968]\n",
      "epoch : 21, loss  14304676.0,  W : [[2.388197]], b  [1.0003043]\n",
      "epoch : 22, loss  12882915.0,  W : [[2.4244454]], b  [1.0003115]\n",
      "epoch : 23, loss  11602465.0,  W : [[2.4588454]], b  [1.0003183]\n",
      "epoch : 24, loss  10449279.0,  W : [[2.491491]], b  [1.0003247]\n",
      "epoch : 25, loss  9410712.0,  W : [[2.522472]], b  [1.0003308]\n",
      "epoch : 26, loss  8475372.0,  W : [[2.551873]], b  [1.0003366]\n",
      "epoch : 27, loss  7632992.0,  W : [[2.5797746]], b  [1.0003421]\n",
      "epoch : 28, loss  6874342.5,  W : [[2.6062534]], b  [1.0003474]\n",
      "epoch : 29, loss  6191095.0,  W : [[2.6313818]], b  [1.0003524]\n",
      "epoch : 30, loss  5575759.5,  W : [[2.6552286]], b  [1.0003572]\n",
      "epoch : 31, loss  5021585.0,  W : [[2.6778595]], b  [1.0003617]\n",
      "epoch : 32, loss  4522487.0,  W : [[2.6993363]], b  [1.000366]\n",
      "epoch : 33, loss  4072997.75,  W : [[2.7197177]], b  [1.00037]\n",
      "epoch : 34, loss  3668185.25,  W : [[2.73906]], b  [1.0003738]\n",
      "epoch : 35, loss  3303606.0,  W : [[2.7574158]], b  [1.0003774]\n",
      "epoch : 36, loss  2975262.5,  W : [[2.7748353]], b  [1.0003809]\n",
      "epoch : 37, loss  2679557.0,  W : [[2.7913666]], b  [1.0003841]\n",
      "epoch : 38, loss  2413242.25,  W : [[2.8070548]], b  [1.0003872]\n",
      "epoch : 39, loss  2173397.5,  W : [[2.821943]], b  [1.0003902]\n",
      "epoch : 40, loss  1957389.125,  W : [[2.836072]], b  [1.0003929]\n",
      "epoch : 41, loss  1762852.125,  W : [[2.8494804]], b  [1.0003955]\n",
      "epoch : 42, loss  1587650.125,  W : [[2.862205]], b  [1.000398]\n",
      "epoch : 43, loss  1429861.875,  W : [[2.8742807]], b  [1.0004004]\n",
      "epoch : 44, loss  1287757.5,  W : [[2.8857405]], b  [1.0004027]\n",
      "epoch : 45, loss  1159778.0,  W : [[2.896616]], b  [1.0004048]\n",
      "epoch : 46, loss  1044516.75,  W : [[2.906937]], b  [1.0004069]\n",
      "epoch : 47, loss  940711.625,  W : [[2.9167314]], b  [1.0004088]\n",
      "epoch : 48, loss  847224.9375,  W : [[2.9260263]], b  [1.0004106]\n",
      "epoch : 49, loss  763030.25,  W : [[2.9348474]], b  [1.0004123]\n",
      "epoch : 50, loss  687203.25,  W : [[2.9432187]], b  [1.000414]\n",
      "epoch : 51, loss  618911.5,  W : [[2.951163]], b  [1.0004156]\n",
      "epoch : 52, loss  557408.25,  W : [[2.9587023]], b  [1.0004171]\n",
      "epoch : 53, loss  502017.53125,  W : [[2.965857]], b  [1.0004185]\n",
      "epoch : 54, loss  452132.875,  W : [[2.972647]], b  [1.0004199]\n",
      "epoch : 55, loss  407205.8125,  W : [[2.9790905]], b  [1.0004212]\n",
      "epoch : 56, loss  366745.1875,  W : [[2.9852054]], b  [1.0004224]\n",
      "epoch : 57, loss  330305.625,  W : [[2.9910085]], b  [1.0004236]\n",
      "epoch : 58, loss  297488.0,  W : [[2.9965158]], b  [1.0004246]\n",
      "epoch : 59, loss  267931.84375,  W : [[3.0017421]], b  [1.0004257]\n",
      "epoch : 60, loss  241313.359375,  W : [[3.006702]], b  [1.0004267]\n",
      "epoch : 61, loss  217340.703125,  W : [[3.0114088]], b  [1.0004276]\n",
      "epoch : 62, loss  195750.859375,  W : [[3.0158756]], b  [1.0004284]\n",
      "epoch : 63, loss  176307.078125,  W : [[3.0201147]], b  [1.0004293]\n",
      "epoch : 64, loss  158795.46875,  W : [[3.0241375]], b  [1.0004301]\n",
      "epoch : 65, loss  143024.640625,  W : [[3.0279553]], b  [1.0004308]\n",
      "epoch : 66, loss  128820.8828125,  W : [[3.0315783]], b  [1.0004315]\n",
      "epoch : 67, loss  116029.2109375,  W : [[3.0350165]], b  [1.0004323]\n",
      "epoch : 68, loss  104508.90625,  W : [[3.0382795]], b  [1.0004328]\n",
      "epoch : 69, loss  94133.40625,  W : [[3.041376]], b  [1.0004334]\n",
      "epoch : 70, loss  84789.15625,  W : [[3.0443149]], b  [1.000434]\n",
      "epoch : 71, loss  76373.453125,  W : [[3.0471036]], b  [1.0004346]\n",
      "epoch : 72, loss  68794.4609375,  W : [[3.04975]], b  [1.0004351]\n",
      "epoch : 73, loss  61969.078125,  W : [[3.0522616]], b  [1.0004356]\n",
      "epoch : 74, loss  55822.03125,  W : [[3.054645]], b  [1.0004361]\n",
      "epoch : 75, loss  50285.828125,  W : [[3.056907]], b  [1.0004365]\n",
      "epoch : 76, loss  45299.96484375,  W : [[3.0590537]], b  [1.000437]\n",
      "epoch : 77, loss  40809.2734375,  W : [[3.0610907]], b  [1.0004374]\n",
      "epoch : 78, loss  36765.30859375,  W : [[3.063024]], b  [1.0004377]\n",
      "epoch : 79, loss  33122.96875,  W : [[3.0648587]], b  [1.0004381]\n",
      "epoch : 80, loss  29842.845703125,  W : [[3.0665998]], b  [1.0004385]\n",
      "epoch : 81, loss  26888.5703125,  W : [[3.068252]], b  [1.0004388]\n",
      "epoch : 82, loss  24228.154296875,  W : [[3.0698202]], b  [1.0004392]\n",
      "epoch : 83, loss  21832.001953125,  W : [[3.0713084]], b  [1.0004394]\n",
      "epoch : 84, loss  19673.884765625,  W : [[3.0727205]], b  [1.0004396]\n",
      "epoch : 85, loss  17730.4921875,  W : [[3.0740607]], b  [1.0004399]\n",
      "epoch : 86, loss  15980.2314453125,  W : [[3.0753324]], b  [1.0004401]\n",
      "epoch : 87, loss  14404.0361328125,  W : [[3.0765393]], b  [1.0004404]\n",
      "epoch : 88, loss  12984.494140625,  W : [[3.0776846]], b  [1.0004406]\n",
      "epoch : 89, loss  11705.9970703125,  W : [[3.0787716]], b  [1.0004408]\n",
      "epoch : 90, loss  10554.5712890625,  W : [[3.0798032]], b  [1.0004411]\n",
      "epoch : 91, loss  9517.46875,  W : [[3.0807822]], b  [1.0004413]\n",
      "epoch : 92, loss  8583.5224609375,  W : [[3.0817113]], b  [1.0004416]\n",
      "epoch : 93, loss  7742.3173828125,  W : [[3.082593]], b  [1.0004417]\n",
      "epoch : 94, loss  6984.78369140625,  W : [[3.0834296]], b  [1.0004418]\n",
      "epoch : 95, loss  6302.6201171875,  W : [[3.0842237]], b  [1.0004419]\n",
      "epoch : 96, loss  5688.078125,  W : [[3.0849774]], b  [1.000442]\n",
      "epoch : 97, loss  5134.64697265625,  W : [[3.0856924]], b  [1.0004421]\n",
      "epoch : 98, loss  4636.3466796875,  W : [[3.0863712]], b  [1.0004423]\n",
      "epoch : 99, loss  4187.44140625,  W : [[3.0870152]], b  [1.0004424]\n",
      "epoch : 100, loss  3783.264404296875,  W : [[3.0876265]], b  [1.0004425]\n",
      "epoch : 101, loss  3419.159912109375,  W : [[3.0882065]], b  [1.0004426]\n",
      "epoch : 102, loss  3091.279052734375,  W : [[3.088757]], b  [1.0004427]\n",
      "epoch : 103, loss  2795.978759765625,  W : [[3.0892794]], b  [1.0004429]\n",
      "epoch : 104, loss  2530.057861328125,  W : [[3.089775]], b  [1.000443]\n",
      "epoch : 105, loss  2290.599365234375,  W : [[3.0902455]], b  [1.0004431]\n",
      "epoch : 106, loss  2074.93359375,  W : [[3.090692]], b  [1.0004432]\n",
      "epoch : 107, loss  1880.6446533203125,  W : [[3.0911157]], b  [1.0004433]\n",
      "epoch : 108, loss  1705.7125244140625,  W : [[3.091518]], b  [1.0004435]\n",
      "epoch : 109, loss  1548.1156005859375,  W : [[3.0918994]], b  [1.0004436]\n",
      "epoch : 110, loss  1406.2593994140625,  W : [[3.0922616]], b  [1.0004437]\n",
      "epoch : 111, loss  1278.4552001953125,  W : [[3.092605]], b  [1.0004438]\n",
      "epoch : 112, loss  1163.397705078125,  W : [[3.0929313]], b  [1.0004439]\n",
      "epoch : 113, loss  1059.735595703125,  W : [[3.0932407]], b  [1.000444]\n",
      "epoch : 114, loss  966.3959350585938,  W : [[3.0935345]], b  [1.000444]\n",
      "epoch : 115, loss  882.3200073242188,  W : [[3.0938132]], b  [1.000444]\n",
      "epoch : 116, loss  806.610595703125,  W : [[3.0940778]], b  [1.000444]\n",
      "epoch : 117, loss  738.3883056640625,  W : [[3.0943289]], b  [1.000444]\n",
      "epoch : 118, loss  676.97265625,  W : [[3.094567]], b  [1.000444]\n",
      "epoch : 119, loss  621.67626953125,  W : [[3.094793]], b  [1.000444]\n",
      "epoch : 120, loss  571.8782348632812,  W : [[3.0950077]], b  [1.000444]\n",
      "epoch : 121, loss  527.01318359375,  W : [[3.0952113]], b  [1.000444]\n",
      "epoch : 122, loss  486.61065673828125,  W : [[3.0954044]], b  [1.000444]\n",
      "epoch : 123, loss  450.244873046875,  W : [[3.0955877]], b  [1.000444]\n",
      "epoch : 124, loss  417.4803771972656,  W : [[3.0957618]], b  [1.000444]\n",
      "epoch : 125, loss  387.96112060546875,  W : [[3.095927]], b  [1.000444]\n",
      "epoch : 126, loss  361.3687438964844,  W : [[3.0960836]], b  [1.000444]\n",
      "epoch : 127, loss  337.4438781738281,  W : [[3.0962324]], b  [1.000444]\n",
      "epoch : 128, loss  315.8786315917969,  W : [[3.0963736]], b  [1.000444]\n",
      "epoch : 129, loss  296.4631042480469,  W : [[3.0965075]], b  [1.000444]\n",
      "epoch : 130, loss  278.9712219238281,  W : [[3.0966346]], b  [1.000444]\n",
      "epoch : 131, loss  263.2278747558594,  W : [[3.0967553]], b  [1.000444]\n",
      "epoch : 132, loss  249.04327392578125,  W : [[3.0968697]], b  [1.000444]\n",
      "epoch : 133, loss  236.27525329589844,  W : [[3.0969784]], b  [1.000444]\n",
      "epoch : 134, loss  224.76312255859375,  W : [[3.0970814]], b  [1.000444]\n",
      "epoch : 135, loss  214.4112091064453,  W : [[3.0971792]], b  [1.000444]\n",
      "epoch : 136, loss  205.08934020996094,  W : [[3.0972722]], b  [1.000444]\n",
      "epoch : 137, loss  196.6737823486328,  W : [[3.0973604]], b  [1.000444]\n",
      "epoch : 138, loss  189.09765625,  W : [[3.097444]], b  [1.000444]\n",
      "epoch : 139, loss  182.2764129638672,  W : [[3.0975235]], b  [1.000444]\n",
      "epoch : 140, loss  176.1358184814453,  W : [[3.0975988]], b  [1.000444]\n",
      "epoch : 141, loss  170.6063232421875,  W : [[3.0976703]], b  [1.000444]\n",
      "epoch : 142, loss  165.62472534179688,  W : [[3.0977383]], b  [1.000444]\n",
      "epoch : 143, loss  161.13377380371094,  W : [[3.0978026]], b  [1.000444]\n",
      "epoch : 144, loss  157.09414672851562,  W : [[3.0978637]], b  [1.000444]\n",
      "epoch : 145, loss  153.46221923828125,  W : [[3.0979216]], b  [1.000444]\n",
      "epoch : 146, loss  150.18887329101562,  W : [[3.0979767]], b  [1.000444]\n",
      "epoch : 147, loss  147.23590087890625,  W : [[3.098029]], b  [1.000444]\n",
      "epoch : 148, loss  144.57894897460938,  W : [[3.0980785]], b  [1.000444]\n",
      "epoch : 149, loss  142.185302734375,  W : [[3.0981255]], b  [1.000444]\n",
      "epoch : 150, loss  140.03245544433594,  W : [[3.09817]], b  [1.000444]\n",
      "epoch : 151, loss  138.09527587890625,  W : [[3.0982125]], b  [1.000444]\n",
      "epoch : 152, loss  136.343017578125,  W : [[3.0982528]], b  [1.000444]\n",
      "epoch : 153, loss  134.76573181152344,  W : [[3.098291]], b  [1.000444]\n",
      "epoch : 154, loss  133.34800720214844,  W : [[3.0983272]], b  [1.000444]\n",
      "epoch : 155, loss  132.07122802734375,  W : [[3.0983615]], b  [1.000444]\n",
      "epoch : 156, loss  130.92221069335938,  W : [[3.0983942]], b  [1.000444]\n",
      "epoch : 157, loss  129.88478088378906,  W : [[3.0984251]], b  [1.000444]\n",
      "epoch : 158, loss  128.95152282714844,  W : [[3.0984545]], b  [1.000444]\n",
      "epoch : 159, loss  128.1127471923828,  W : [[3.0984824]], b  [1.000444]\n",
      "epoch : 160, loss  127.35533142089844,  W : [[3.0985088]], b  [1.000444]\n",
      "epoch : 161, loss  126.67378234863281,  W : [[3.0985339]], b  [1.000444]\n",
      "epoch : 162, loss  126.06236267089844,  W : [[3.0985577]], b  [1.000444]\n",
      "epoch : 163, loss  125.51022338867188,  W : [[3.0985804]], b  [1.000444]\n",
      "epoch : 164, loss  125.01140594482422,  W : [[3.0986018]], b  [1.000444]\n",
      "epoch : 165, loss  124.56441497802734,  W : [[3.098622]], b  [1.000444]\n",
      "epoch : 166, loss  124.16155242919922,  W : [[3.0986414]], b  [1.000444]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 167, loss  123.80029296875,  W : [[3.0986598]], b  [1.000444]\n",
      "epoch : 168, loss  123.4708480834961,  W : [[3.0986772]], b  [1.000444]\n",
      "epoch : 169, loss  123.1771469116211,  W : [[3.0986936]], b  [1.000444]\n",
      "epoch : 170, loss  122.91143798828125,  W : [[3.0987093]], b  [1.000444]\n",
      "epoch : 171, loss  122.67230224609375,  W : [[3.0987241]], b  [1.000444]\n",
      "epoch : 172, loss  122.4588394165039,  W : [[3.0987382]], b  [1.000444]\n",
      "epoch : 173, loss  122.26547241210938,  W : [[3.0987515]], b  [1.000444]\n",
      "epoch : 174, loss  122.0922622680664,  W : [[3.0987642]], b  [1.000444]\n",
      "epoch : 175, loss  121.93470764160156,  W : [[3.0987763]], b  [1.000444]\n",
      "epoch : 176, loss  121.79179382324219,  W : [[3.0987878]], b  [1.000444]\n",
      "epoch : 177, loss  121.66484069824219,  W : [[3.0987985]], b  [1.000444]\n",
      "epoch : 178, loss  121.55154418945312,  W : [[3.0988088]], b  [1.000444]\n",
      "epoch : 179, loss  121.44792175292969,  W : [[3.0988185]], b  [1.000444]\n",
      "epoch : 180, loss  121.35638427734375,  W : [[3.0988278]], b  [1.000444]\n",
      "epoch : 181, loss  121.27061462402344,  W : [[3.0988367]], b  [1.000444]\n",
      "epoch : 182, loss  121.19587707519531,  W : [[3.098845]], b  [1.000444]\n",
      "epoch : 183, loss  121.12852478027344,  W : [[3.0988529]], b  [1.000444]\n",
      "epoch : 184, loss  121.06761932373047,  W : [[3.0988605]], b  [1.000444]\n",
      "epoch : 185, loss  121.01102447509766,  W : [[3.0988677]], b  [1.000444]\n",
      "epoch : 186, loss  120.96128845214844,  W : [[3.0988743]], b  [1.000444]\n",
      "epoch : 187, loss  120.91671752929688,  W : [[3.0988808]], b  [1.000444]\n",
      "epoch : 188, loss  120.8761978149414,  W : [[3.098887]], b  [1.000444]\n",
      "epoch : 189, loss  120.83924865722656,  W : [[3.0988927]], b  [1.000444]\n",
      "epoch : 190, loss  120.8086166381836,  W : [[3.0988982]], b  [1.000444]\n",
      "epoch : 191, loss  120.7787857055664,  W : [[3.0989034]], b  [1.000444]\n",
      "epoch : 192, loss  120.75152587890625,  W : [[3.0989084]], b  [1.000444]\n",
      "epoch : 193, loss  120.72736358642578,  W : [[3.0989132]], b  [1.000444]\n",
      "epoch : 194, loss  120.70602416992188,  W : [[3.0989177]], b  [1.000444]\n",
      "epoch : 195, loss  120.68576049804688,  W : [[3.098922]], b  [1.000444]\n",
      "epoch : 196, loss  120.6689453125,  W : [[3.098926]], b  [1.000444]\n",
      "epoch : 197, loss  120.65251159667969,  W : [[3.09893]], b  [1.000444]\n",
      "epoch : 198, loss  120.63806915283203,  W : [[3.0989335]], b  [1.000444]\n",
      "epoch : 199, loss  120.62706756591797,  W : [[3.0989368]], b  [1.000444]\n"
     ]
    }
   ],
   "source": [
    "#Model y=X*W + b\n",
    "#Model function\n",
    "def output(x):\n",
    "    return W*x + b\n",
    "\n",
    "#Loss function Reduce mean square\n",
    "def loss_function(y_pred, y_true):\n",
    "    return tf.reduce_mean(tf.square(y_pred - y_true))\n",
    "\n",
    "#Initialize Weights\n",
    "W = tf.Variable(tf.random.uniform(shape=(1, 1)))\n",
    "b = tf.Variable(tf.ones(shape=(1,)))\n",
    "\n",
    "#Optimization\n",
    "## Writing training/learing loop with GradienTape\n",
    "learning_rate = 0.000000001\n",
    "steps = 200 #epochs\n",
    "\n",
    "for i in range(steps):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = output(x_train)\n",
    "        loss = loss_function(predictions,y_train)\n",
    "        dloss_dw, dloss_db = tape.gradient(loss, [W, b])\n",
    "    W.assign_sub(learning_rate * dloss_dw)\n",
    "    b.assign_sub(learning_rate * dloss_db)\n",
    "    print(f\"epoch : {i}, loss  {loss.numpy()},  W : {W.numpy()}, b  {b.numpy()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('w ', W)\n",
    "print('b ', b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize Weights\n",
    "W = tf.Variable(tf.random.uniform(shape=(1, 1)))\n",
    "b = tf.Variable(tf.ones(shape=(1,)))\n",
    "\n",
    "#Optimization\n",
    "## Writing training/learing loop with GradienTape\n",
    "learning_rate = 0.000000001\n",
    "steps = 200 #epochs\n",
    "\n",
    "for i in range(steps):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = output(x_train)\n",
    "        loss = loss_function(predictions,y_train)\n",
    "        dloss_dw, dloss_db = tape.gradient(loss, [W, b])\n",
    "    W.assign_sub(learning_rate * dloss_dw)\n",
    "    b.assign_sub(learning_rate * dloss_db)\n",
    "    if i%30 == 0:\n",
    "        print(f\"epoch is: {i}, loss is {loss.numpy()},  W is: {W.numpy()}, b is {b.numpy()}\")\n",
    "        plt.title([\"epoch\", i])\n",
    "        plt.plot(x_train, y_train, 'b.')\n",
    "        plt.plot(x_train, output(x_train), c='r')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression Model building in TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This step is for data creation\n",
    "x_train= np.random.rand(100,1)\n",
    "y_train=np.array([0 if i < 0.5 else 1 for i in x_train]).reshape(-1,1)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.title(\"x_train vs y_train data\")\n",
    "plt.plot(x_train, y_train, 'b.',)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model y=sigmoid(X*W + b)\n",
    "# same as the linear regression just sigmoid wrapped around the linear equation\n",
    "def output(x): \n",
    "    return tf.sigmoid(W*x + b)\n",
    "\n",
    "#Loss function : sum of squares\n",
    "def loss_function(y_pred, y_true):\n",
    "    return tf.reduce_sum(tf.square(y_pred - y_true))\n",
    "\n",
    "#Initialize Weights\n",
    "W = tf.Variable(tf.random.uniform(shape=(1, 1)))\n",
    "b = tf.Variable(tf.zeros(shape=(1,)))\n",
    "\n",
    "## Optimization\n",
    "learning_rate = 0.1\n",
    "steps = 300 #epochs\n",
    "\n",
    "for i in range(steps):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = output(x_train)\n",
    "        loss = loss_function(y_train, predictions)\n",
    "        dloss_dw, dloss_db = tape.gradient(loss, [W, b])\n",
    "    W.assign_sub(learning_rate * dloss_dw)\n",
    "    b.assign_sub(learning_rate * dloss_db)\n",
    "    print(f\"epoch : {i}, loss  {loss.numpy()},  W : {W.numpy()}, b  {b.numpy()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model y=X*W + b\n",
    "# same as the linear regression just sigmoid wrapped around the linear equation\n",
    "def output(x): \n",
    "    return tf.sigmoid(W*x + b)\n",
    "\n",
    "#Loss function : sum of squares\n",
    "def loss_function(y_pred, y_true):\n",
    "    return tf.reduce_sum(tf.square(y_pred - y_true))\n",
    "\n",
    "#Initialize Weights\n",
    "W = tf.Variable(tf.random.uniform(shape=(1, 1)))\n",
    "b = tf.Variable(tf.zeros(shape=(1,)))\n",
    "\n",
    "## Optimization\n",
    "learning_rate = 0.1\n",
    "steps = 300 #epochs\n",
    "\n",
    "for i in range(steps):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = output(x_train)\n",
    "        loss = loss_function(y_train, predictions)\n",
    "        dloss_dw, dloss_db = tape.gradient(loss, [W, b])\n",
    "    W.assign_sub(learning_rate * dloss_dw)\n",
    "    b.assign_sub(learning_rate * dloss_db)\n",
    "\n",
    "    if i%40 == 0:\n",
    "        print(f\"epoch is: {i}, loss is {loss.numpy()},  W is: {W.numpy()}, b is {b.numpy()}\")\n",
    "        plt.title([\"epoch\", i])\n",
    "        plt.plot(x_train, y_train, 'b+')\n",
    "        plt.plot(x_train, output(x_train), '.', c='r')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## The data, shuffled and split between train and test sets\n",
    "(X_train, Y_train), (X_test, Y_test) = keras.datasets.mnist.load_data()\n",
    "num_classes=10\n",
    "x_train = X_train.reshape(60000, 784)\n",
    "x_test = X_test.reshape(10000, 784)\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "## Convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(Y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(Y_test, num_classes)\n",
    "\n",
    "print(x_train.shape, 'train input samples')\n",
    "print(x_test.shape, 'test input samples')\n",
    "\n",
    "print(y_train.shape, 'train output samples')\n",
    "print(y_test.shape, 'test output samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot 4 images as gray scale\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.subplot(221)\n",
    "plt.imshow(X_train[1], cmap=plt.get_cmap('gray'))\n",
    "plt.subplot(222)\n",
    "plt.imshow(X_train[6], cmap=plt.get_cmap('gray'))\n",
    "plt.subplot(223)\n",
    "plt.imshow(X_train[7], cmap=plt.get_cmap('gray'))\n",
    "plt.subplot(224)\n",
    "plt.imshow(X_train[9], cmap=plt.get_cmap('gray'))\n",
    "\n",
    "# show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "#Input Layer. The model needs to know what input shape it should expect. \n",
    "#For this reason, the first layer in a Sequential model needs to receive information about its input shape.\n",
    "#Only the first need the snape information, because following layers can do automatic shape inference\n",
    "model.add(layers.Dense(20, activation='sigmoid', input_shape=(784,)))\n",
    "\n",
    "#The dense layer is simply a layer where each unit or neuron is connected to each neuron in the next layer.\n",
    "model.add(layers.Dense(20, activation='sigmoid'))\n",
    "\n",
    "#In the final layer mention the output classes\n",
    "model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "#Model Summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling model : we define loss function, optimizer and validation matric of our choice\n",
    "model.compile(loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Fit method: actually running our model by supplying our input and validation data\n",
    "model.fit(x_train, y_train,epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, acc = model.evaluate(x_test,  y_test, verbose=2)\n",
    "print(\"Test Accuracy: {:5.2f}%\".format(100*acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
